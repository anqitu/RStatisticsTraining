# printcp(cart_prune, digits = 3)
prp(cart_prune, type=2, cex = 0.4, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
prob_train <- predict(cart_prune, type='prob')
prob_test <- predict(cart_prune, type='prob', newdata = test)
write.csv(prob_train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Train_Cart_Prune.csv", row.names = FALSE)
write.csv(prob_test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Test_Cart_Prune.csv", row.names = FALSE)
# print(cart_prune)
# printcp(cart_prune, digits = 3)
prp(cart_prune, type=2, cex = 0.7, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
# print(cart_prune)
# printcp(cart_prune, digits = 3)
prp(cart_prune, type=2, cex = 0.5, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
# print(cart_prune)
# printcp(cart_prune, digits = 3)
prp(cart_prune, type=2, cex = 0.4, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
# print(cart_prune)
# printcp(cart_prune, digits = 3)
prp(cart_prune, type=2, cex = 0.5, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
summary_mars
summary_mars$coefficients
summary_mars$coefficients
prob_train <- predict(mars, type='response')
max(prob_train)
min(prob_train)
min(prob_test)
max(prob_test)
summary_mars$coefficients
# start <- Sys.time()
summary_full_lr = summary(full_lr)
users <- read.csv("/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/data/users_r.csv")
summary(users)
users$date_account_created_month <- factor(users$date_account_created_month, levels = 1: 12,
labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
"Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))
users$date_first_active_month <- factor(users$date_first_active_month, levels = 1: 12,
labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
"Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))
# Generate a random number sequence that can be reproduced to check results thru the seed number.
set.seed(2019)
library(neuralnet)
set.seed(2014)  # for random starting weights
# Neural Network comprising 1 hidden layer with 2 hidden nodes for binary categorical target
nn <- neuralnet(country_destination~., data=train, hidden=2, err.fct="ce", linear.output=FALSE)
# Try Train vs Test set split.
library(caTools)
# Generate a random number sequence that can be reproduced to check results thru the seed number.
set.seed(2019)
# Randomly split data into two sets in predefined ratio while preserving relative ratios of different categories of Y in both sets.
attach((users))
split <- sample.split(Y = users, SplitRatio = 0.7)
# Get training and test data
train <- subset(users, split == T)
test <- subset(users, split == F)
# Neural Network comprising 1 hidden layer with 2 hidden nodes for binary categorical target
nn <- neuralnet(country_destination~., data=train, hidden=2, err.fct="ce", linear.output=FALSE)
flags = data.frame(Reduce(cbind,
lapply(levels(train$gender), function(x){(train$gender == x)*1})
))
flags
names(flags) = levels(train$gender)
d = cbind(train, flags)
levels(train$gender)
lapply(levels(train$gender), function(x){(train$gender == x)*1})
names(flags) = levels(train$gender)
levels(train$gender)
'gender' + levels(train$gender)
class.ind(as.factor(train$gender))
require(nnet)
class.ind(as.factor(train$gender))
d = cbind(train, class.ind(as.factor(train$gender)))
# Include the new columns as input variables
levelnames = paste(names(flags), collapse = " + ")
levelnames
# lr0 <- multinom(country_destination ~ 1, data = train,  MaxNWts =10000000) # null model with no X.
# step_lr <- step(lr0, direction = "forward", scope = formula(full_fit_lr), data = train)
start <- Sys.time()
step_lr <- multinom(formula = country_destination ~ affiliate_provider +
age_bkt + date_account_created_month + language + gender +
first_affiliate_tracked + first_device + affiliate_channel +
signup_app + first_browser, data = train, MaxNWts = 1e+07)
start <- Sys.time()
LR_Step_OR.CI <- exp(confint(full_lr))
end <- Sys.time()
time_df$LR_Step_OR.CI <- end - start
LR_Step_OR.CI
start <- Sys.time()
LR_Step_OR.CI <- exp(confint(step_lr))
full_lr <- multinom(country_destination ~ ., data = train, MaxNWts =10000000)
lr0 <- multinom(country_destination ~ 1, data = train,  MaxNWts =10000000) # null model with no X.
step_lr <- step(lr0, direction = "forward", scope = formula(full_fit_lr), data = train)
step_lr <- step(lr0, direction = "forward", scope = formula(full_lr), data = train)
step_lr
start <- Sys.time()
step_lr <- multinom(formula = country_destination ~ affiliate_channel +
age_bkt + date_first_active_month + language + gender +
first_device, data = train, MaxNWts = 1e+07)
end <- Sys.time()
time_df$LR_Step <- end - start
prob_train <- predict(step_lr, type = 'prob')
prob_test <- predict(step_lr, newdata = test, type = 'prob')
write.csv(prob_train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Train_LR_Step.csv", row.names = FALSE)
write.csv(prob_test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Test_LR_Step.csv", row.names = FALSE)
end - start
time_df <- data.frame(row.names = 'run time')
time_df$LR_Step <- end - start
start <- Sys.time()
full_lr <- multinom(country_destination ~ ., data = train, MaxNWts =10000000)
end <- Sys.time()
time_df$LR_Full <- end - start
library(rpart)
library(rpart.plot)			# For Enhanced tree plots via PRP()
set.seed(2019)
options(digits = 3)
# default cp = 0.01. Set cp = 0 to guarantee no pruning in order to complete phrase 1: Grow tree to max.
start <- Sys.time()
cart_full <- rpart(country_destination ~ ., data = train, method = 'class', control = rpart.control(minsplit = 2, cp = 0))
end <- Sys.time()
time_df$Cart_Full <- end - start
prob_train <- predict(cart_full, type='prob')
prob_test <- predict(cart_full, type='prob', newdata = test)
write.csv(prob_train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Train_Cart_Full.csv", row.names = FALSE)
write.csv(prob_test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Test_Cart_Full.csv", row.names = FALSE)
cart_full$cptable
cart_full$cptable[which.min(cart_full$cptable[,"xerror"]),"CP"]
# cart_prune <- prune(cart_full, cp = cp.opt)
cart_prune <- prune(cart_full, cp = 1.12e-04)
start <- Sys.time()
# cart_prune <- prune(cart_full, cp = cp.opt)
cart_prune <- prune(cart_full, cp = 1.12e-04)
end <- Sys.time()
time_df$Cart_Prune <- end - start + time_df$Cart_Full
prob_train <- predict(cart_prune, type='prob')
prob_test <- predict(cart_prune, type='prob', newdata = test)
write.csv(prob_train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Train_Cart_Prune.csv", row.names = FALSE)
write.csv(prob_test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Test_Cart_Prune.csv", row.names = FALSE)
cart_prune$variable.importance
cart_full$variable.importance
cart_full$cptable
cart_prune <- prune(cart_full, cp = 9.54e-05)
cart_full$variable.importance
cart_prune$variable.importance
# print(cart_prune)
# printcp(cart_prune, digits = 3)
# prp(cart_prune, type=2, cex = 0.5, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
cart_prune$variable.importance
cart_prune <- prune(cart_full, cp = 1.10e-04)
# print(cart_prune)
# printcp(cart_prune, digits = 3)
# prp(cart_prune, type=2, cex = 0.5, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
cart_prune$variable.importance
write.csv(cart_prune$variable.importance, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/cart_prune_vi.csv", row.names = FALSE)
write.csv(cart_prune$variable.importance, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/cart_prune_vi.csv")
cart_full$cptable
# cart_prune <- prune(cart_full, cp = cp.opt)
cart_prune <- prune(cart_full, cp = 1.12e-04)
# print(cart_prune)
# printcp(cart_prune, digits = 3)
# prp(cart_prune, type=2, cex = 0.5, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
cart_prune$variable.importance
library(randomForest)
start <- Sys.time()
randomForest <- randomForest(country_destination ~ ., data = train, method = 'class', randomForest = TRUE,
ntree = 100,importance=TRUE)
end <- Sys.time()
time_df$Random_Forest <- end - start
prob_train <- predict(randomForest, type='prob')
prob_test <- predict(randomForest, type='prob', newdata = test)
write.csv(prob_train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Train_Random_Forest.csv", row.names = FALSE)
write.csv(prob_test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Test_Random_Forest.csv", row.names = FALSE)
importance(randomForest)
randomForest$importance
varImpPlot(randomForest)
library(randomForest)
start <- Sys.time()
randomForest <- randomForest(country_destination ~ ., data = train, method = 'class', randomForest = TRUE, ntree = 1)
end <- Sys.time()
time_df$Random_Forest <- end - start
importance(randomForest)
varImpPlot(randomForest)
library(randomForest)
start <- Sys.time()
randomForest <- randomForest(country_destination ~ ., data = train, method = 'class', randomForest = TRUE, ntree = 100)
end <- Sys.time()
time_df$Random_Forest <- end - start
prob_train <- predict(randomForest, type='prob')
prob_test <- predict(randomForest, type='prob', newdata = test)
write.csv(prob_train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Train_Random_Forest.csv", row.names = FALSE)
write.csv(prob_test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Test_Random_Forest.csv", row.names = FALSE)
randomForest$importance
importance(randomForest)
write.csv(randomForest$importance, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/forest_vi.csv")
varImpPlot(randomForest)
library(randomForest)
start <- Sys.time()
randomForest <- randomForest(country_destination ~ ., data = train, method = 'class', randomForest = TRUE, ntree = 100)
end <- Sys.time()
time_df$Random_Forest <- end - start
prob_train <- predict(randomForest, type='prob')
prob_test <- predict(randomForest, type='prob', newdata = test)
write.csv(prob_train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Train_Random_Forest.csv", row.names = FALSE)
write.csv(prob_test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Test_Random_Forest.csv", row.names = FALSE)
varImpPlot(randomForest)
write.csv(randomForest$importance, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/forest_vi.csv")
library(earth)
start <- Sys.time()
mars <- earth(country_destination~., nfold=10,  data=train, glm=list(family=binomial), degree=2)
end <- Sys.time()
time_df$Mars <- end - start
prob_train <- predict(mars, type='response')
prob_test <- predict(mars, type='response', newdata = test)
write.csv(prob_train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Train_Mars.csv", row.names = FALSE)
write.csv(prob_test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Prob_Test_Mars.csv", row.names = FALSE)
time_df$Mars <- time_df$Mars * 60
time_df$Random_Forest <- time_df$Random_Forest * 60
write.csv(time_df, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/Run_Time_R.csv", row.names = FALSE)
summary_mars <- summary(mars)
summary_mars$coefficients
# # plotd(mars)
# start <- Sys.time()
ev <- evimp (mars)
ev
plotmo(mars)
plotmo(mars, nresponse = 1)
ev
write.csv(evimp (mars), file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/mars_vi.csv")
write.csv(evimp(mars), file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/mars_vi.csv")
plot(evimp(mars))
evimp(mars)
users <- read.csv("/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/data/users_r.csv")
summary(users)
users$date_account_created_month <- factor(users$date_account_created_month, levels = 1: 12,
labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
"Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))
users$date_first_active_month <- factor(users$date_first_active_month, levels = 1: 12,
labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
"Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))
# Try Train vs Test set split.
library(caTools)
# Generate a random number sequence that can be reproduced to check results thru the seed number.
set.seed(2019)
# Randomly split data into two sets in predefined ratio while preserving relative ratios of different categories of Y in both sets.
attach((users))
split <- sample.split(Y = users, SplitRatio = 0.7)
# Get training and test data
train <- subset(users, split == T)
test <- subset(users, split == F)
# write.csv(train, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/train_r_from_r.csv", row.names = FALSE)
# write.csv(test, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/test_r_from_r.csv", row.names = FALSE)
time_df <- data.frame(row.names = 'run time')
library(rpart)
library(rpart.plot)			# For Enhanced tree plots via PRP()
set.seed(2019)
options(digits = 3)
cart_full <- rpart(country_destination ~ ., data = train, method = 'class', control = rpart.control(minsplit = 2, cp = 0))
# cart_prune <- prune(cart_full, cp = 1.12e-04)
cart_prune <- prune(cart_full, cp = 1.10e-04)
# print(cart_prune)
# printcp(cart_prune, digits = 3)
# prp(cart_prune, type=2, cex = 0.5, extra=104, nn=T, fallen.leaves=T, branch.lty=3, nn.box.col = 'light blue', min.auto.cex = 0.7, nn.cex = 0.6, split.cex = 1.1, shadow.col="grey")
cart_prune$variable.importance
randomForest <- randomForest(country_destination ~ ., data = train, method = 'class', randomForest = TRUE, ntree = 100)
library(randomForest)
randomForest <- randomForest(country_destination ~ ., data = train, method = 'class', randomForest = TRUE, ntree = 100)
randomForest$importance
write.csv(randomForest$importance, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/forest_vi.csv")
library(earth)
mars <- earth(country_destination~., nfold=10,  data=train, glm=list(family=binomial), degree=2)
write.csv(summary_mars$coefficients, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/mars_coef.csv")
summary_mars <- summary(mars)
summary_mars$coefficients
write.csv(summary_mars$coefficients, file = "/Users/anqitu/Workspaces/NTU/Airbnb-new-user-bookings/training_result/mars_coef.csv")
library(tidytext)
# Loop
# While loop
x <- 1
while (x<10) {
print(x)
x <- x+1
}
# For loop
for (i in c(3,8,2) ) {
print(i)
}
for (i in 1:10) {
if (i == 4) {next}
print(i)
}
for (i in 1:10) {
if (i == 4) {break}
print(i)
}
for (i in 1:10) {
if (i == 4) {next}
print(i)
}
for (i in 1:10) {
if (i == 4) {break}
print(i)
}
# Ex: Conditional & Loop
a <- read.csv("weather.csv",header=TRUE)
setwd('/Users/anqitu/Workspaces/Tertiary-Courses/RStatisticsTraining/exercises')
# Ex: Conditional & Loop
a <- read.csv("weather.csv",header=TRUE)
b <- subset(a,select=c("Temp","Month"))
c <- subset(b,Month==5 | Month==6)
temp <- c$Temp
count <-0
for (i in temp ) {
if (i>65) {
count <- count +1
}
}
length(temp[temp>65])
TRUE && TRUE
TRUE & TRUE
1 & TRUE
1 && TRUE
c <- subset(b,Month==5 || Month==6)
c
# Ex: Conditional & Loop
a <- read.csv("weather.csv",header=TRUE)
b <- subset(a,select=c("Temp","Month"))
c <- subset(b,Month==5 || Month==6)
temp <- c$Temp
count <-0
for (i in temp ) {
if (i>65) {
count <- count +1
}
}
length(temp[temp>65])
# Ex: Conditional & Loop
a <- read.csv("weather.csv",header=TRUE)
b <- subset(a,select=c("Temp","Month"))
c <- subset(b,Month==5 | Month==6)
c <- subset(b,Month==5 || Month==6)
View(c)
c <- subset(b,Month==5 | Month==6)
1==1 || 2==2
1==2 || 2==2
1==2 && 2==2
x <- c(TRUE,FALSE,0,6)
y <- c(FALSE,TRUE,FALSE,TRUE)
!x
x&y
x&&y
x|y
x||y
y <- function(x) {
x*x
}
y(2)
filter <- function(x) {
x[x>0]
}
filter(-10:10)
f <- function(x=3,y=4) {
x*2+y*3
}
f()
f <- function(x,y) {
x*x+y*y*y
}
f(x=3,y=2)
f(x=2,y=3)
f <- function(x,y,...) {
plot(x,y,...)
}
roll <- function() {
dice<-sample(1:6,2)
sum(dice)
}
f(x,y,col="red",main="sine")
f(1:10,1:10,col="red",main="sine")
f(1:10,1:10,col="red")
roll <- function() {
dice<-sample(1:6,2)
sum(dice)
}
roll()
roll()
roll()
# Descriptive Statistics
data <- c(3,NA,4,6,NA,10,2)
mean(data,trim=0.1)
mean(data,na.rm = TRUE)
summary(data)
mean(data,trim=0.1)
mean(data,trim=0.3)
mean(data,trim=0.5)
mean(data,trim=0.1)
mean(data)
mean(data,na.rm = TRUE)
mean(data,trim=0.1, na.rm = TRUE)
mean(data,trim=0.3,na.rm = TRUE)
mean(data,trim=0.2,na.rm = TRUE)
summary(data)
#Correlation
data <- mtcars[,c(1,3,6)]
cor(data$mpg,data$wt)
round(cor(data),2)
round(cor(quakes),2)
# Linear Regression
x <- 1:5
y <- c(1.3,4.3,5.5,8.4,14.2)
plot(x,y)
m <- lm(y~x)
summary(m)
predict(m,data.frame(x=6))
predict(m)
# Fitting linear model
m <- lm(mpg ~ wt, data = mtcars)
# Intercept and Slope
coef(m)
summary(m)
# Prediction
p <- predict(m, data.frame(wt = 3))
# Prediction
p <- predict(m)
p <- predict(m, newdata = data.frame(wt = 3))
# Prediction
p <- predict(m)
p <- predict(m, newdata = data.frame(wt = 3))
# Prediction
predict(m)
# Fitting linear model
plt(mtcars$wt, mtcars$mpg)
# Fitting linear model
plot(mtcars$wt, mtcars$mpg)
m <- lm(mpg ~ wt, data = mtcars)
# Intercept and Slope
coef(m)
summary(m)
# Prediction
predict(m)
predict(m, newdata = data.frame(wt = 3))
plot(mgp~wt,data=mtcars)
plot(mpg~wt,data=mtcars)
abline(m)
# Ex: Linear Regression
x <- quakes$stations
y <- quakes$mag
plot(x,y)
m <- lm(y~x)
abline(m)
predict(m,data.frame(x=100))
abline(m, color = 'blu')
abline(m, col = 'blue')
abline(m, col = 'r')
abline(m, col = 'red')
m <- lm(y~x)
abline(m, col = 'red')
# Ex: Linear Regression
x <- quakes$stations
y <- quakes$mag
plot(x,y)
m <- lm(y~x)
abline(m, col = 'red')
predict(m,data.frame(x=100))
# Multiple Regression
round(cor(mtcars[,1:5]),2)
# Multiple Regression
round(cor(mtcars,2)
# Multiple Regression
round(cor(mtcars,2))
round(cor(mtcars,2))
# Multiple Regression
round(cor(mtcars), 1)
# Multiple Regression
round(cor(mtcars), 2)
# Multiple Regression
corr <- round(cor(mtcars), 2)
corr$mpg
corr
type(corr)
str(corr)
data.frame(corr)
data.frame(corr)$mpg
m <- lm(mpg~wt+hp,data=mtcars)
predict(m,data.frame(wt=3,hp=200))
m <- lm(mpg ~ wt*hp, data = mtcars)
summary(m)
p<- predict(m, data.frame(wt = 3, hp = 200))
predict(m, data.frame(wt = 3, hp = 200))
boxplot(extra~group,data=sleep)
t.test(extra~group,data=sleep,alternative="less")
t.test(extra~group,data=sleep)
t.test(extra~group,data=sleep,alternative="less")
t.test(extra~group,data=sleep)
# Challenge: t-Test
boxplot(weight~feed,data=chickwts)
d <- subset(chickwts,feed == "casein" | feed =="horsebean")
t.test(weight~feed,data=d)
# ANOVA
m <- aov(weight~feed,data=chickwts)
summary(m)
# ANOVA
m <- aov(weight~feed,data=chickwts)
summary(m)
m <- lm(weight~feed,data=chickwts)
summary(m)
# Ex: ANOVA
teaching <- data.frame(
method = rep(c('A','B','C'),each=4),
score = c(79,86,94,89,71,77,81,83,82,68,70,76)
)
teaching
m <- aov(score~method,data=teaching)
summary(m)
boxplot(score~method,data=teaching)
summary(m)
